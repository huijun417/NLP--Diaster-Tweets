# NLP--Diaster-Tweets



we investigate the effect of 
LSTMs and pre-trained models such as BERT, 
RoBERTa and a couple of variations of those models on 
the effect of disaster tweet detection. The performance 
of the models used are documented based on F1 scores, 
a measure of accuracy in binary classification. Our 
paper finds that BERTweet obtained the best model 
performance of 85.9%
